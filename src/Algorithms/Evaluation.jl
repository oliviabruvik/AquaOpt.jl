include("../Models/KalmanFilter.jl")
include("../Models/SeaLicePOMDP.jl")
include("../Models/SeaLiceLogPOMDP.jl")
include("../Models/SimulationPOMDP.jl")
include("../Models/SimulationLogPOMDP.jl")
include("../Utils/Config.jl")
include("Policies.jl")
include("Simulation.jl")

using GaussianFilters
using POMDPs
using POMDPModels
using POMDPTools
using POMDPXFiles
using DataFrames
using JLD2
using Plots
using Distributions
using Parameters

# ----------------------------
# Create POMDP and MDP for a given lambda
# ----------------------------
function create_pomdp_mdp(λ, config)

    # Create directory for POMDP and MDP
    pomdp_mdp_dir = joinpath(config.data_dir, "pomdp_mdp")
    mkpath(pomdp_mdp_dir)

    if config.log_space
        pomdp = SeaLiceLogMDP(
            lambda=λ,
            costOfTreatment=config.costOfTreatment,
            growthRate=config.growthRate,
            rho=config.rho,
            discount_factor=config.discount_factor,
            skew=config.skew
        )
    else
        pomdp = SeaLiceMDP(
            lambda=λ,
            costOfTreatment=config.costOfTreatment,
            growthRate=config.growthRate,
            rho=config.rho,
            discount_factor=config.discount_factor,
            skew=config.skew
        )
    end

    mdp = UnderlyingMDP(pomdp)

    # Save POMDP and MDP to file
    pomdp_mdp_filename = "pomdp_mdp_$(λ)_lambda"
    pomdp_mdp_file_path = joinpath(pomdp_mdp_dir, "$(pomdp_mdp_filename).jld2")
    @save pomdp_mdp_file_path pomdp mdp

    # Save POMDP as POMDPX file for NUS SARSOP
    pomdpx_file_path = joinpath(pomdp_mdp_dir, "pomdp.pomdpx")
    pomdpx = POMDPXFile(pomdpx_file_path)
    POMDPXFiles.write(pomdp, pomdpx)

    return pomdp, mdp
end

# ----------------------------
# Generate MDP and POMDP policies
# ----------------------------
function generate_mdp_pomdp_policies(algorithm, config)

    policies_dir = joinpath(config.data_dir, "policies", "$(algorithm.solver_name)")
    mkpath(policies_dir)

    # Generate policies for each lambda
    for λ in config.lambda_values

        # Generate POMDP and MDP
        pomdp, mdp = create_pomdp_mdp(λ, config)

        # Generate policy
        policy = generate_policy(algorithm, pomdp, mdp)

        # Save policy, pomdp, and mdp to file
        policy_pomdp_mdp_filename = "policy_pomdp_mdp_$(λ)_lambda"
        @save joinpath(policies_dir, "$(policy_pomdp_mdp_filename).jld2") policy pomdp mdp

    end
end


# ----------------------------
# Simulate policy
# ----------------------------
function simulate_policy(algorithm, config)

    # Create directory for simulation histories
    histories_dir = joinpath(config.data_dir, "simulation_histories", "$(algorithm.solver_name)")
    mkpath(histories_dir)

    # Create directory for policies
    policies_dir = joinpath(config.data_dir, "policies", "$(algorithm.solver_name)")
    mkpath(policies_dir)

    histories = DataFrame(
        lambda=Float64[],
        state_hists=Vector{Any}[],
        action_hists=Vector{Any}[],
        belief_hists=Vector{Any}[],
        r_total_hists=Vector{Any}[],
        measurement_hists=Vector{Any}[],
        reward_hists=Vector{Any}[]
    )

    # Simulate policy
    for λ in config.lambda_values

        # Load policy, pomdp, and mdp
        policy_pomdp_mdp_filename = "policy_pomdp_mdp_$(λ)_lambda"
        @load joinpath(policies_dir, "$(policy_pomdp_mdp_filename).jld2") policy pomdp mdp

        # Simulate policy
        r_total_hists, action_hists, state_hists, measurement_hists, reward_hists, belief_hists = run_simulation(policy, mdp, pomdp, config, algorithm)
        push!(histories, (λ, state_hists, action_hists, belief_hists, r_total_hists, measurement_hists, reward_hists))

    end

    # Save results
    histories_filename = "$(algorithm.solver_name)_histories"
    @save joinpath(histories_dir, "$(histories_filename).jld2") histories
    
    return histories
end

# ----------------------------
# Calculate averages
# ----------------------------
function evaluate_simulation_results(config, algorithm, histories)

    # Create directory for simulation histories
    histories_dir = joinpath(config.data_dir, "simulation_histories", "$(algorithm.solver_name)")
    histories_filename = "$(algorithm.solver_name)_histories"

    avg_results_dir = joinpath(config.data_dir, "avg_results")
    mkpath(avg_results_dir)
    
    @load joinpath(histories_dir, "$(histories_filename).jld2") histories

    avg_results = DataFrame(
        lambda=Float64[],
        avg_treatment_cost=Float64[],
        avg_sealice=Float64[],
        avg_reward=Float64[],
    )

    for λ in config.lambda_values

        # Get histories for this lambda
        histories_lambda = histories[histories.lambda .== λ, :]

        # Get action, state, and reward histories
        action_hists = histories_lambda.action_hists[1]
        state_hists = histories_lambda.state_hists[1]
        reward_hists = histories_lambda.reward_hists[1]

        avg_reward, avg_treatment_cost, avg_sealice = calculate_averages(config, action_hists, state_hists, reward_hists)

        # Calculate the average reward, cost, and sea lice level
        push!(avg_results, (λ, avg_treatment_cost, avg_sealice, avg_reward))

    end

    # Save results
    avg_results_filename = "$(algorithm.solver_name)_avg_results"
    @save joinpath(avg_results_dir, "$(avg_results_filename).jld2") avg_results
    
    return avg_results
end